{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "formal-seating",
   "metadata": {},
   "source": [
    "# <center>Radial Basis Function (RBF) Implementation</center>\n",
    "<center>Ankush Bhayekar (gq8442)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-viewer",
   "metadata": {},
   "source": [
    "#### The breast cancer data csv file is downloaded from :\n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the breast cancer csv file\n",
    "data = pd.read_csv('data.csv', usecols=[*range(1, 31)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting diagnosis column to the binary dummies - if malignant then M = 1 else 0\n",
    "diagnosis = pd.get_dummies(data['diagnosis'],drop_first=True)\n",
    "# dropping original column with M and N values\n",
    "data.drop(['diagnosis'],axis=1,inplace=True)\n",
    "# concatinate the Binary diagnosis data column to dataframe\n",
    "data = pd.concat([data,diagnosis],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pandas dataframe to numpy array\n",
    "data_np = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-burden",
   "metadata": {},
   "source": [
    "*For training purpose 60% of the data set split and used. Test data is kept at 20%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per = int(round(data_np.shape[0] * 0.6, -1))\n",
    "test_per = int(round(data_np.shape[0] * 0.2, -1))\n",
    "vald_per = int(round(data_np.shape[0] * 0.2, -1))\n",
    "\n",
    "# 60% of the data is splitted for the training of the model\n",
    "y_train = data_np[0:train_per, -1] \n",
    "X_train = data_np[0:train_per, 0:-1]\n",
    "# 20% of the data is splitted for the testing purpose\n",
    "y_test = data_np[train_per+1:train_per+test_per, -1]\n",
    "X_test = data_np[train_per+1:train_per+test_per, 0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dist(centr, x):\n",
    "    '''\n",
    "    function to calculate the Euclidian distance between the random centroid \n",
    "    and cluster data points\n",
    "    '''\n",
    "    summ = 0\n",
    "    for indx in range(len(centr)):\n",
    "        summ += (centr[indx] - x[indx]) ** 2\n",
    "    return np.sqrt(summ)\n",
    "\n",
    "\n",
    "def k_means_centroid(X, k, max_iters):\n",
    "    \"\"\"\n",
    "    This function returns the cluster centers and standard deviation of the clusters.\n",
    "    The function converges when the previous centroids sum and current centroids sum goes to zero\n",
    "    \"\"\"\n",
    "  \n",
    "    clust_centroids = X[np.random.choice(range(len(X)), k, replace=False)]\n",
    "\n",
    "    convergd = False\n",
    "    \n",
    "    cur_iteration = 0\n",
    "\n",
    "    while (not convergd) and (cur_iteration < max_iters):\n",
    "\n",
    "        cluster_list = [[] for i in range(len(clust_centroids))]\n",
    "\n",
    "        for x in X:  # Go through each data point\n",
    "            euc_distances = []\n",
    "            for c in clust_centroids:\n",
    "                euc_distances.append(euclid_dist(c, x))\n",
    "            cluster_list[int(np.argmin(euc_distances))].append(x)\n",
    "\n",
    "        cluster_list = list((filter(None, cluster_list)))\n",
    "\n",
    "        prior_centroids = clust_centroids.copy()\n",
    "\n",
    "        clust_centroids = []\n",
    "\n",
    "        for j in range(len(cluster_list)):\n",
    "            clust_centroids.append(np.mean(cluster_list[j], axis=0))\n",
    "\n",
    "        converg_crit = np.abs(np.sum(prior_centroids) - np.sum(clust_centroids))\n",
    "\n",
    "        convergd = (converg_crit == 0)\n",
    "\n",
    "        cur_iteration += 1\n",
    "\n",
    "    return np.array(clust_centroids), [np.std(x) for x in cluster_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rbf_net:\n",
    "\n",
    "    def __init__(self, X_train, y_train, X_tr, y_tr, num_of_classes, k, clusters_std=True):\n",
    "        self.X_tr = X_train\n",
    "        self.y_tr = y_train\n",
    "        self.X_test = X_tr\n",
    "        self.y_test = y_tr\n",
    "        self.clusters_std = clusters_std\n",
    "        self.no_of_class = num_of_classes\n",
    "        self.k = k\n",
    "\n",
    "    def eucd_rbf(self, x, sent, std):\n",
    "        euc_dis = euclid_dist(x, sent)\n",
    "        return 1 / np.exp(-euc_dis / std ** 2)\n",
    "\n",
    "    def rbflayer(self, X, grp_cent, stand_dev):\n",
    "        layer_list = []\n",
    "        for x in X:\n",
    "            layer_list.append([self.eucd_rbf(x, or_g, std) for (or_g, std) in zip(grp_cent, stand_dev)])\n",
    "        return np.array(layer_list)\n",
    "    \n",
    "    def dummy_var(self, x, no_of_class):\n",
    "        dum_arr = np.zeros((len(x), no_of_class))\n",
    "        for idx in range(len(x)):\n",
    "            gcent = int(x[idx])\n",
    "            dum_arr[idx][gcent] = 1\n",
    "        return dum_arr\n",
    "    \n",
    "    def netfit(self):\n",
    "\n",
    "        self.clust_centroids, self.stand_dev = k_means_centroid(self.X_tr, self.k, max_iters=1000)\n",
    "\n",
    "        if not self.clusters_std:\n",
    "            Max_eucd = np.max([euclid_dist(c1, c2) for c1 in self.clust_centroids for c2 in self.clust_centroids])\n",
    "            self.stand_dev = np.repeat(Max_eucd / np.sqrt(2 * self.k), self.k)\n",
    "        \n",
    "        # using same Beta for all the cluster centroids\n",
    "        rbfnet_x = self.rbflayer(self.X_tr, self.clust_centroids, self.stand_dev)\n",
    "        # get the rbfnet of the input x and apply LS Optimization to estimate weight matrix 'weights'\n",
    "        self.weights = np.linalg.pinv(rbfnet_x.T @ rbfnet_x) @ rbfnet_x.T @ self.dummy_var(self.y_tr, self.no_of_class)\n",
    "\n",
    "        rbf_test = self.rbflayer(self.X_test, self.clust_centroids, self.stand_dev)\n",
    "\n",
    "        self.y_pred = rbf_test @ self.weights\n",
    "\n",
    "        self.y_pred = np.array([np.argmax(x) for x in self.y_pred])\n",
    "\n",
    "        error = self.y_pred - self.y_test\n",
    "        \n",
    "        # Confusion Matrix calculation\n",
    "        \n",
    "        fp = 0\n",
    "        tp = 0\n",
    "        fn = 0\n",
    "        \n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] == 1 and self.y_test[i] == 0:\n",
    "                fp += 1\n",
    "            elif self.y_pred[i] == 0 and self.y_test[i] == 1:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        \n",
    "        precision = tp / (tp+fp)\n",
    "        recall = tp / (tp+fn)\n",
    "        F_1_score = (2*precision*recall) / (precision+recall)\n",
    "\n",
    "        print('\\n***** Confusion Matrix ******\\n')\n",
    "        print('Accuracy: ', round(len(np.where(error == 0)[0]) / len(error) ,3))\n",
    "        print('Precision: ', round(precision,3))\n",
    "        print('Recall: ', round(recall,3))\n",
    "        print('F-1 Score: ', round(F_1_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_class = rbf_net(X_train, y_train, X_test, y_test, num_of_classes=29, k=10, clusters_std=False)\n",
    "rbf_class.netfit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-ensemble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-figure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
